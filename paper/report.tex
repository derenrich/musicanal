\documentclass[a4paper,10pt]{article}
\usepackage[utf8x]{inputenc}
\usepackage{ismir2011,amsmath,cite}

%opening
\title{Metric Learning For Music Similarity}
\author{Daniel \{Rosenberg, Erenrich\} }

\begin{document}
\maketitle

\begin{abstract}
Automatic music classification is an important problem in music analysis. While it is difficult to say what exactly makes a certain genre of music unique, identifying genres gives you a distinct advantage in recommending songs. In this paper, we use data from the Million Song dataset provided by The Echo Nest. We extracted a subset of the features provided, and ran KNN on the data after performing widening.
\end{abstract}

\section{Introduction}
Machine music analysis is a growing field in both industry and academia. One of the major difficulties with this work is that it requires large labeled corpuses which are difficult to obtain. The relatively new ``Million Song Dataset'' provides the music analysis community an opportunity to scale research to very large datasets with little organizational difficulty\cite{Bertin-Mahieux2011}. Already many papers of capitalized on this data to to solve such problems as playlist generation\cite{mcfee2011_nlp}, music classification and song cover-identification\cite{Bertin-Mahieux2011b}. 

Music similarity algorithms are especially useful because they can be used as subcomponents of algorithms like cover-identification and playlist generation. Previous work on music analysis was often performed on datasets as small as just 5000 songs\cite{Slaney_learninga}. It is now important that we reevaluate these techniques to determine how these algorithms scale in terms of accuracy and speed. It is not immediately obvious that all of our music metric-learning techniques will be able to scale. Others have already shown algorithmic techniques to speed up basic metrics of music similarity\cite{mcfee2011_sim}.

We performed metric learning across the ``Million Song Dataset'' in order to determine song similarity. As a ground truth for similarity we used both artist and genre as labels.
\section{Data representation}
\subsection{Audio representation}
The ``Million Song Dataset'' provides features and metadata for a million songs as generated by the ``EchoNest's'' music analysis software. This data includes such information as volume, length and beats per minute. In order to fit the entire dataset in memory and effectively work with it we projected down to a much smaller set of features. This set of features was strongly influenced by \cite{Slaney_learninga} though we chose to drop several features as they are not consistantly populated across the dataset. Less than one percent of the dataset appears to be invalid or improperly populated since some values are clearly incorrect. For example. songs which are listed as having zero beats were dropped from the analysis.

\begin{itemize}
 \item Song length
 \item Mean segment length
 \item Segment length variance
 \item Mean segment loudness
 \item Segment loudness variance
 \item Third quartile of max segment loudness 
 \item First quartile of max segment loundess
 \item Mean segment begin loudness
 \item Segment begin loudness variance
 \item Beat interval variance
 \item Tatum confidence
 \item Mean tatum length
 \item Tatums per beat
 \item Time signature
 \item Time signature confidence
 \item Song mode
 \item Song mode confidence
 \item Pitch covariance matrix
 \item Pitch coocurence counts
\end{itemize}

By eliminating all features that vary with time along the song the dimensionality of the data is reduced 308 numbers. This means that the 500GB dataset becomes just 1GB in size and so is much easier to analyze. Exactly how much information has been lost in the transformation is unclear. 
\subsection{Data labels}
We used two different types of labels in our experiments as ground-truth for music similarity. Songs are alternately considered ``similar'' if they share a common artist, if they share a certain number of music tags as provided by EchoNest or if the artists share similar genres depending.
\section{Algorithms}
\subsection{Whitening}
It has been shown throughout the literature that first whitening the dataset in order to ensure that the covariance matrix of the data is the identity matrix improves performance. We use KNN using euclidean distance and cosine similarity in conjunction with and without whitening. 

Here we show our results on a compressed version of the dataset which only includes the top 500 most frequent artists and 25000 songs. This was done to decrease artist sparsity.
\begin{center}
\begin{tabular}{lllll}
KNN & Euclidean & Euclidean Whitened & Cosine & Cosine Whitened\\
1 & 12.3\% & 19.3\% & 14.8\% & \\
3 &  &  &  & \\
5 &  &  &  & 
\end{tabular}
\end{center}


\section{References}
\bibliography{refs}{}
\end{document}
